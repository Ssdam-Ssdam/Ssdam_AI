{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8655f8-0333-43ea-b771-a0c8cc11f2ed",
   "metadata": {},
   "source": [
    "- 데이터 증강을 train data에만 적용하려 했으나, test data에도 적용됨  \n",
    "    => 이를 해결하면 성능 개선 가능\n",
    "- 데이터 파일도 한 번 다시 살펴보고 성능을 저하시킬만한 퀄리티가 안좋은 이미지 데이터 제거해야 함\n",
    "- 하이퍼파라미터튜닝도 추후에 진행\n",
    "- label 불균형 해소  \n",
    "=> 데이터 증강 활용\n",
    "- label 선택하기\n",
    "- label: [TV 받침, 거울, 빨래건조대, 서랍장, 쇼파, 시계, 안마의자, 의자, 자전거, 장롱, 장식장, 진열대, 책꽂이, 책상, 책장, 침대, 테이블, 피아노, 화장대]\n",
    "- 설계서에 이미지 중복된 데이터 제거한 거 담기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b6d2b2-7977-4c8e-9ecf-4feb0590c0ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 5479\n",
      "Validation dataset size: 684\n",
      "Test dataset size: 686\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "# 데이터셋 경로\n",
    "data_dir = r'C:/Users/lej55/ssdamssdam/data/duplicate_data/merged_data'\n",
    "\n",
    "# 전처리 및 데이터 증강 함수 정의\n",
    "class CustomTransform:\n",
    "    def __init__(self, augment=False):\n",
    "        self.augment = augment\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # 기본적인 이미지 전처리 (크기 조정, 텐서 변환, 정규화)\n",
    "        img = transforms.Resize((224, 224))(img)  # 이미지 크기 조정\n",
    "        img = transforms.ToTensor()(img)  # 텐서로 변환\n",
    "        img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)  # 정규화\n",
    "        \n",
    "        # 데이터 증강 (훈련 데이터에서만 적용)\n",
    "        if self.augment:\n",
    "            # 랜덤 좌우 반전\n",
    "            if random.random() > 0.5:\n",
    "                img = F.hflip(img)\n",
    "            \n",
    "            # 랜덤 회전\n",
    "            angle = random.randint(-30, 30)\n",
    "            img = F.rotate(img, angle)\n",
    "\n",
    "            # 랜덤 밝기 조정\n",
    "            brightness = random.uniform(0.5, 1.5)\n",
    "            img = F.adjust_brightness(img, brightness)\n",
    "            \n",
    "            # 랜덤 크롭\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(img, output_size=(224, 224))\n",
    "            img = F.crop(img, i, j, h, w)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "# 데이터셋 로딩 (전체 데이터 로딩)\n",
    "transform = CustomTransform(augment=False)  # 증강 없이 전처리만 적용\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# 데이터셋을 훈련, 검증, 테스트 데이터로 분할\n",
    "train_size = int(0.8 * len(dataset))  # 80% 훈련 데이터\n",
    "val_size = int(0.1 * len(dataset))    # 10% 검증 데이터\n",
    "test_size = len(dataset) - train_size - val_size  # 나머지 10% 테스트 데이터\n",
    "\n",
    "# 랜덤하게 데이터셋을 나눕니다\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# 훈련 데이터에 데이터 증강을 적용\n",
    "train_transform = CustomTransform(augment=True)  # 훈련 데이터는 데이터 증강\n",
    "train_dataset.dataset.transform = train_transform  # 훈련 데이터셋에 증강을 적용\n",
    "\n",
    "# 검증 및 테스트 데이터는 증강 없이 전처리만 적용\n",
    "val_transform = CustomTransform(augment=False)  # 검증 데이터셋에는 전처리만 적용\n",
    "test_transform = CustomTransform(augment=False)  # 테스트 데이터셋에는 전처리만 적용\n",
    "\n",
    "val_dataset.dataset.transform = val_transform  # 검증 데이터셋에 전처리만 적용\n",
    "test_dataset.dataset.transform = test_transform  # 테스트 데이터셋에 전처리만 적용\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터셋 크기 확인\n",
    "print(f\"Train dataset size: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_loader.dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e181959-921d-4f41-b4af-c9fb8fcdd80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "Train Loss: 2.4348 \n",
      " \t Acc: 0.3913\n",
      "Validation Loss: 1.8752 \n",
      " \t Acc: 0.6711\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "Train Loss: 1.5351 \n",
      " \t Acc: 0.6474\n",
      "Validation Loss: 1.2443 \n",
      " \t Acc: 0.7661\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "Train Loss: 1.1282 \n",
      " \t Acc: 0.7290\n",
      "Validation Loss: 0.9697 \n",
      " \t Acc: 0.7836\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "Train Loss: 0.9370 \n",
      " \t Acc: 0.7629\n",
      "Validation Loss: 0.8479 \n",
      " \t Acc: 0.7939\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "Train Loss: 0.8109 \n",
      " \t Acc: 0.7868\n",
      "Validation Loss: 0.7748 \n",
      " \t Acc: 0.7909\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "Train Loss: 0.7402 \n",
      " \t Acc: 0.8012\n",
      "Validation Loss: 0.7196 \n",
      " \t Acc: 0.8158\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "Train Loss: 0.6847 \n",
      " \t Acc: 0.8085\n",
      "Validation Loss: 0.6784 \n",
      " \t Acc: 0.8129\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "Train Loss: 0.6248 \n",
      " \t Acc: 0.8288\n",
      "Validation Loss: 0.6376 \n",
      " \t Acc: 0.8202\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "Train Loss: 0.5861 \n",
      " \t Acc: 0.8341\n",
      "Validation Loss: 0.6387 \n",
      " \t Acc: 0.8187\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "Train Loss: 0.5608 \n",
      " \t Acc: 0.8387\n",
      "Validation Loss: 0.5954 \n",
      " \t Acc: 0.8363\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8557\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 불러오기 (EfficientNet-B0)\n",
    "model = timm.create_model('efficientnet_b0', pretrained=True)\n",
    "\n",
    "# 마지막 Fully Connected Layer (FC) 수정 (Fine-tuning)\n",
    "num_ftrs = model.classifier.in_features  # 기존 FC layer의 입력 차원\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),  # 첫 번째 FC layer\n",
    "    nn.ReLU(),  # ReLU 활성화 함수\n",
    "    nn.Dropout(0.5),  # Dropout 추가\n",
    "    nn.Linear(512, len(dataset.classes))  # 클래스 개수만큼 출력\n",
    ")\n",
    "\n",
    "# 모델 파라미터 freeze (classifier 제외)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False  # 모든 파라미터 freeze\n",
    "\n",
    "# classifier 파라미터만 학습하도록 설정\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수와 옵티마이저 설정\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)  # optimizer는 classifier 파라미터만 사용\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)  # 학습률 스케줄러\n",
    "\n",
    "# 훈련 함수\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # 훈련 단계\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        corrects = 0\n",
    "        total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 통계 계산\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = corrects.double() / total\n",
    "\n",
    "        print(f\"Train Loss: {epoch_loss:.4f} \\n \\t Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        # 검증 단계\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_corrects = 0\n",
    "        val_total = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # 통계 계산\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                val_corrects += torch.sum(preds == labels.data)\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_acc = val_corrects.double() / val_total\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss:.4f} \\n \\t Acc: {val_acc:.4f}\\n\")\n",
    "\n",
    "        # 학습률 스케줄러 변경 (검증 성능 개선시만 적용)\n",
    "        # 모델이 개선되면 모델 가중치를 저장\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = model.state_dict()\n",
    "            scheduler.step()  # 성능 개선이 있을 때만 학습률을 변경\n",
    "\n",
    "\n",
    "    # 최종적으로 학습한 가장 좋은 모델 가중치 로드\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "# 모델 학습\n",
    "trained_model = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=10)\n",
    "\n",
    "# 테스트 데이터셋 평가\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"\\nTest Accuracy: {acc:.4f}\")\n",
    "    \n",
    "# 테스트 데이터 평가\n",
    "evaluate_model(trained_model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f67af58a-6963-4f77-8bf3-ef4cfc878006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as efficientnet_b0_best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "torch.save(trained_model.state_dict(), \"best_trained_model_v1.pth\")\n",
    "print(\"Model saved as best_trained_model_v1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f39768ae-eac8-4f9b-ab31-db1307559dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label: 침대\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 이미지 예측 함수\n",
    "def predict_image(image_path, model, transform, class_names):\n",
    "    \"\"\"\n",
    "    한 장의 이미지를 모델에 입력해 예측\n",
    "    :param image_path: 예측할 이미지 경로\n",
    "    :param model: 학습된 모델\n",
    "    :param transform: 이미지 전처리 함수\n",
    "    :param class_names: 클래스 이름 리스트\n",
    "    \"\"\"\n",
    "    # 이미지를 열고 전처리 적용\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = transform(img)\n",
    "    \n",
    "    # 배치 차원 추가\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    # 모델을 평가 모드로 전환\n",
    "    model.eval()\n",
    "\n",
    "    # GPU 사용 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # 모델에 이미지 입력\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    # 예측 결과 반환\n",
    "    predicted_label = class_names[predicted_class.item()]\n",
    "    return predicted_label\n",
    "\n",
    "\n",
    "# 이미지 경로 설정\n",
    "image_path = r\"C:/Users/lej55/Downloads/새 폴더/의자.jpg\"  # 예측할 이미지 경로\n",
    "\n",
    "# 전처리 함수 (훈련 시 사용했던 전처리 함수와 동일하게 설정)\n",
    "transform = CustomTransform(augment=False)\n",
    "\n",
    "# 클래스 이름 리스트\n",
    "class_names = dataset.classes\n",
    "\n",
    "# 예측 실행\n",
    "predicted_label = predict_image(image_path, trained_model, transform, class_names)\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9cd1cc57-5b15-4ecd-994e-16fa54cd5bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: TV 받침대.jpg, Predicted Label: 서랍장\n",
      "Image: 서랍장.jpg, Predicted Label: 진열대\n",
      "Image: 쇼파.jpg, Predicted Label: 침대\n",
      "Image: 의자.jpg, Predicted Label: 침대\n",
      "Image: 의자2.jpg, Predicted Label: 의자\n",
      "Image: 장롱.jpg, Predicted Label: 장롱\n",
      "Image: 진열대.jpg, Predicted Label: 책꽂이\n",
      "Image: 책상.jpg, Predicted Label: 책상\n",
      "Image: 화장대.jpg, Predicted Label: 화장대\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# 이미지 예측 함수\n",
    "def predict_image(image_path, model, transform, class_names):\n",
    "    \"\"\"\n",
    "    한 장의 이미지를 모델에 입력해 예측\n",
    "    :param image_path: 예측할 이미지 경로\n",
    "    :param model: 학습된 모델\n",
    "    :param transform: 이미지 전처리 함수\n",
    "    :param class_names: 클래스 이름 리스트\n",
    "    \"\"\"\n",
    "    # 이미지를 열고 전처리 적용\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = transform(img)\n",
    "    \n",
    "    # 배치 차원 추가\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    # 모델을 평가 모드로 전환\n",
    "    model.eval()\n",
    "\n",
    "    # GPU 사용 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    img = img.to(device)\n",
    "\n",
    "    # 모델에 이미지 입력\n",
    "    with torch.no_grad():\n",
    "        output = model(img)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "\n",
    "    # 예측 결과 반환\n",
    "    predicted_label = class_names[predicted_class.item()]\n",
    "    return predicted_label\n",
    "\n",
    "# 이미지 폴더 경로 설정\n",
    "image_folder = r\"C:/Users/lej55/Downloads/새 폴더\"  # 예측할 이미지가 있는 폴더 경로\n",
    "\n",
    "# 전처리 함수 (훈련 시 사용했던 전처리 함수와 동일하게 설정)\n",
    "transform = CustomTransform(augment=False)\n",
    "\n",
    "# 클래스 이름 리스트\n",
    "class_names = dataset.classes\n",
    "\n",
    "# 이미지 폴더 내 모든 이미지 파일을 순차적으로 예측\n",
    "for image_name in os.listdir(image_folder):\n",
    "    # 이미지 파일 경로 생성\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    \n",
    "    # 파일이 이미지 파일인지 확인 (확장자 필터링)\n",
    "    if image_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        # 예측 실행\n",
    "        predicted_label = predict_image(image_path, trained_model, transform, class_names)\n",
    "        print(f\"Image: {image_name}, Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3bfd1-276c-47ec-a93a-272ac87860ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
